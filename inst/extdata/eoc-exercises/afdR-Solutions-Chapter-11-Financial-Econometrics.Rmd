---
title: "Analyzing Financial and Economic Data with R"
author: "Marcelo S. Perlin"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
subtitle: 'Chapter 11 - Financial Econometrics with R'
---

```{r setup, include=FALSE}
book.site <- 'https://www.msperlin.com/blog/publication/2017_book-pafdr-en/'
book.site.zip <- 'https://www.msperlin.com/blog/files/pafdr%20files/Code_Data_pafdR.zip'

knitr::opts_chunk$set(message = FALSE)
```


## Exercises

**01. Simulate the following linear process in R:**

```{r}
set.seed (5)

# number of obs
nT <- 100

# set x as Normal (0, 1)
x <- rnorm (nT)

# set coefficients
my_alpha <- 1.5
my_beta <- 0.5

# build y
y <- my_alpha + my_beta * x + rnorm (nT, sd = 5)
```

**Using the simulated data, `x` and `y` estimate a linear model where `x` is the explanatory variable, and `y` is the explained variable. Use the `summary` function on the returned object from `lm` to find more details about the model. Is the beta coefficient significant at 5%?**

```{r}
library(tidyverse)

my_lm <- lm(formula = y ~ x, data = tibble(x, y))

summary(my_lm)
```

Yes, the beta coefficient is significant at 5%.

**02. Using package `car` and the data we previously simulated, test the joint hypothesis that the value of alpha equals to 1.5 and beta equals to 0.5. Is the null hypothesis of the test rejected at 5%?**

```{r}
library(car)

# set test matrix
test_matrix <- matrix(c(my_alpha,  # alpha test value
                        my_beta))  # beta test value

# hypothesis matrix 
hyp_mat <- matrix(c(1.5, 0,
                    0  , 0.5),
                  nrow = 2)

# do test
my_waldtest <- linearHypothesis(my_lm, 
                                hypothesis.matrix = hyp_mat, 
                                rhs = test_matrix)

# print result
print(my_waldtest)
```

Unexpectedly, we fail to reject the null hypothesis that `alpha = 1.5` and `beta=0.5`. The most likely explanation is the low number of observations in the sample. When we increase it to 5000 observations, the null hypothesis of the Wald test was easily rejected.

**03. Use package `gvlma` to test the OLS assumptions for the previously estimated model. Does the model pass all tests? If not, increase the value of `nT` to 5000 and try again. **

```{r}
library(gvlma)

# global validation of model
gvmodel <- gvlma(my_lm) 

# print result
summary(gvmodel)
```

The estimated model passed all tests. 


**04. From package `BatchGetSymbols,` use functions `GetSP500Stocks` and `BatchGetSymbols` to download the past three years price data for all stocks belonging to the current SP500 index. Calculate the systemic risk (beta) for each stock and display the histogram of the estimated _betas_. **

```{r}
library(BatchGetSymbols)
library(tidyverse)

tickers <- GetSP500Stocks()$Tickers
first_date <- Sys.Date() - 3*365
last_date  <- Sys.Date()

df_stocks <- BatchGetSymbols(tickers = tickers, 
                             first.date = first_date, 
                             last.date = last_date)[[2]]

df_sp500 <- BatchGetSymbols(tickers =  '^GSPC', 
                            first.date = first_date, 
                            last.date = last_date)[[2]]

idx <- match(df_stocks$ref.date, df_sp500$ref.date)
df_stocks$ret_mkt <- df_sp500$ret.closing.prices[idx]

# calculate beta for each stock
estimate_beta <- function(df) {
  # Function to estimate beta from dataframe of stocks returns
  #
  # Args:
  #   df - Dataframe with columns ret and ret.sp500
  #
  # Returns:
  #   The value of beta
  
  my_model <- lm(data = df, 
                 formula = ret.adjusted.prices ~ ret_mkt)
  
  return(coef(my_model)[2])
}

my_betas <- by(data = df_stocks, 
               INDICES = df_stocks$ticker, 
               FUN = estimate_beta)

glimpse(my_betas)

# solution
p <- ggplot(tibble(betas = my_betas), aes(x = betas)) + 
  geom_histogram()

print(p)
```

**05. For the same stock data from previous exercise, estimate a panel data version of the market model, that is, each stock has a different _alpha_, but same _beta_. Is the estimated beta significant at 5%?**

```{r}
library(plm)

# estimate panel data model with fixed effects
my_pdm <- plm(data = df_stocks, 
              formula = ret.adjusted.prices ~ ret_mkt, 
              model = 'within',
              index = c('ticker'))

# print result
print(summary(my_pdm))
```

Yes, it is very significant.


**06. Using the tidyverse functions `dplyr::group_by` and `dplyr::do,` estimate an ARIMA(1, 0, 0) model for the returns of each stock using the same data as the previous exercise. On the same `tibble,` create a new column with the return forecast at _t+1_ for each ticker. Which stock has the highest expected return for the next day?**

```{r}
library(dplyr)

my_tab <- df_stocks %>%
  group_by(ticker) %>%
  do(my_arima = arima(x = .$ret.adjusted.prices, 
                      order = c(1,0,0))) %>%
  mutate(arima_forecast = predict(my_arima, n.ahead = 1 )$pred[1])

glimpse(my_tab)

# solution
idx <- which.max(my_tab$arima_forecast )
print(my_tab$ticker[idx])
```


**07. Using the same "pipeline" code as the previous question, use package `fGarch` to add a new list-column with the estimation of an ARMA(1,0)-GARCH(1,1) model for the returns of each stock. Add another column with the volatility forecast (standard deviation) and the return, both at _t + 1_. Increment the table by creating a trade index, the result of dividing the expected return (mean forecast) calculated in the previous item by the predicted risk (standard deviation forecast). Which stock is more attractive and has a higher value of this index? Tip: Ensure that you remove all of the `NA` values before estimating the ARMA-GARCH model. **

```{r}
library(dplyr)
library(fGarch)

tab_models <- df_stocks %>%
  na.omit() %>%
  group_by(ticker) %>%
  do(my_garch = garchFit(formula = ~ arma(1,0) + garch(1,1), 
                         data = .$ret.adjusted.prices, 
                         trace = FALSE) ) 

tab_models <- tab_models %>%
  mutate(forecast_mean = predict(my_garch, 
                                 n.ahead = 1)$meanForecast[1],
         forecast_sd = predict(my_garch, 
                               n.ahead = 1)$standardDeviation[1],
         sharpe_index = forecast_mean/forecast_sd)

glimpse(tab_models)

# solution
idx <- which.max(tab_models$sharpe_index)
print(tab_models$ticker[idx])
```


**08. For the same SP500 database, set `set.seed(10)` and filter data for four randomly selected stocks. Again, make sure all `NA` values are removed from the `dataframe.` For each stock, estimate a simple Markov regime-switching model for its returns. Such a model will have two states for intercept and volatility. The structure of the model is equivalent to the first model in the section "Estimating Regime Switching Models" of chapter 11. Use the `plot` function to display the smoothed probability plot and use `png::jpeg` and `grDevices::dev.off` to save each figure in a folder named `'fig'`.**

```{r}
library(tidyverse)
library(fMarkovSwitching)

set.seed(10)

random_stocks <- sample(unique(df_stocks$ticker), 4)

temp_df <- df_stocks %>%
  dplyr::filter(ticker %in% random_stocks)

  tab_switching_model <- temp_df %>%
  na.omit() %>%
  group_by(ticker) %>%
  do(ms_model = MS_Regress_Fit(dep = .$ret.adjusted.prices,
                               indep = rep(1, nrow(.)),
                               S = c(1), 
                               k = 2))	# fitting the model)


# using temp folder for solution


plot_and_save <- function(model_in, ticker_in) {
  
  if (!dir.exists('figs')) dir.create('figs')
  
  out_file <- file.path('figs', paste0('plot_', ticker_in, '.jpg'))
  
  jpeg(out_file)
  plot(model_in)
  dev.off()
  
  return(TRUE)
  
  
}

library(purrr)

l_out <- pmap(.l = list(model_in = tab_switching_model$ms_model,
                        ticker_in = tab_switching_model$ticker), 
              .f =  plot_and_save)

```


