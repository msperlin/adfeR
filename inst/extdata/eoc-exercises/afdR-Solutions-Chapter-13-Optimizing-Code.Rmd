---
title: "Analyzing Financial and Economic Data with R  "
author: "Marcelo S. Perlin"
date: "`r Sys.Date()`"
output:
  html_document: default
  word_document: default
  pdf_document: default
subtitle: 'Chapter 13 - Optimizing Code'
---

```{r setup, include=FALSE}
book.site <- 'https://www.msperlin.com/blog/publication/2017_book-pafdr-en/'
book.site.zip <- 'https://www.msperlin.com/blog/files/pafdr%20files/Code_Data_pafdR.zip'

knitr::opts_chunk$set(message = FALSE)
```

## Exercises

**01. Consider the following code:**

```{r}
library(tidyverse)
library(forecast)
library(BatchGetSymbols)

ticker <- '^GSPC'
df_prices <- BatchGetSymbols(tickers = ticker, 
                             first.date = '2010-01-01')[[2]]

my_arima <- auto.arima(df_prices$ret.adjusted.prices)
summary(my_arima)
```

**Use `Rprof` and `profvis` to identify the bottleneck of the code. Which line number is taking more time?**

```{r, eval=FALSE}
library(tidyverse)
library(BatchGetSymbols)
library(fGarch)
library(profvis)

# set temporary file for results
profiling_file <-  tempfile(pattern = 'profiling_exercise', 
                            fileext = '.out')

# initialize profiling
Rprof(filename = profiling_file)

# run code
profiling <- profvis(expr = {
  ticker <- '^GSPC'
  df_prices <- BatchGetSymbols(tickers = ticker, 
                               first.date = '2000-01-01', do.cache = FALSE)[[2]]
  
  my_garch <- garchFit(formula = ret.adjusted.prices ~ arma(1,1) + garch(1,1), 
                       data =  na.omit(df_prices) )
})

# create visualization
temp_html <- tempfile(pattern = 'profile',
                      fileext = '.html')

htmlwidgets::saveWidget(profiling, temp_html)

# Can open in browser from R
# browseURL(temp_html)
```

Not surprisingly, the `fGarch::garchFit` function is the one taking  more time. It is likely related to the numerical optimization required to estimate the Garch model.


**02. Use package `Rcpp` to write and use a C++  function that will add elements of vectors `x` and `y`, in a element-by-element fashion. The output should be another vector of same size and with equal elements as `x + y`. Use function `identical` to test if all elements from both vectors are equal. **

```{r}
library(Rcpp)

cppFunction('Rcpp::NumericVector sum_vectors_C(NumericVector x, NumericVector y) {
  int n = x.size();
  
  Rcpp::NumericVector total(x.size());
  
  for(int i = 0; i < n; ++i) {
    total[i] = x[i] + y[i];
  }
  return total;
}')

x <- runif(100)
y <- runif(100)

sol_C <- sum_vectors_C(x, y)
sol_R <- x + y

identical(sol_C, sol_R)
```

**03. Use package `tictoc` to compare the performance of the previous function against R's native `+` operator and a looped version of the function, with prealocation. Who has the least execution time and why? Does the `Rcpp` version wins over the looped version?**

```{r}
library(tictoc)

tic('Using Rcpp')
sol_C <- sum_vectors_C(x, y)
toc()

tic('Using base R')
sol_R <- x + y
toc()

tic('Using a loop and prealocation')
sol_loop <- numeric(length = length(x))
for (i in 1:length(x)) {
  sol_loop[i] <- x[i] + y[i]
}
toc()
```

The alternative with the least execution time is base R. While the Rcpp version did quite well, the base R operator `+` is already calling a lower level function and it is optimized for speed. Worth nothing that the code version using a loop is the slowest, as expected.

**04. Use package `memoise` to create a memorized version of `Quandl::Quandl`. Use the new function to import data for the Consumer Price Index of the United States (code `'FRED/DDOE01USA086NWDB'`). How much of a percentage speed gain you get from the second call to the memorized version?**

```{r}
library(Quandl)
library(memoise)
library(tictoc)

mem_quandl <- memoise(f = Quandl, cache = cache_memory())

id <- 'FRED/DDOE01USA086NWDB'

tic('Using original Quandl')
df <- Quandl(code = id)
toc()

tic('Using memoise version (first call)')
df <- mem_quandl(code = id)
toc()

tic('Using memoise version (second call)')
df <- mem_quandl(code = id)
a <- toc()


```


