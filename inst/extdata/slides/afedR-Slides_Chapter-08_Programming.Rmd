---
title: "Analyzing Financial and Economic Data with R"
subtitle: "Chapter 08 - Programming and Data Analysis"
author: "Marcelo S. Perlin"
date: "2020-02-15"
output:
  slidy_presentation: default
  ioslides_presentation: default
  beamer_presentation: default

---

## Introduction {#introduction}

```{r, include=FALSE}
my.fig.height <- 3
my.fig.width <- 4
my.out.width <- '100%'
book.site.zip <- 'https://www.msperlin.com/blog/static/afedr-files/afedr_files.zip'

format.cash <- function(x) {
  require(scales)

  x.formatted <- dollar(x,
                        prefix = '$',
                        decimal.mark = '.',
                        big.mark = ',',
                        largest_with_cents = Inf)

  return(x.formatted)
}

```

Here we will learn how to use programming tools to analyze our data:

- creation of custom functions;
- structured repetition of code (_loops_)
- conditional execution. 

R offers a complete programming environment. So, based on it, you will be able to solve any computational problem from the real world. 


## R Functions

**The use of functions is in the heart of R**. Using functions organizes the code and its applicability. It also makes it easy to fix bugs and errors. 


A function always has three parts: input, processing stage, and output.

```{r}
example_fct <- function(arg1 = 1, arg2 = 'abc'){
  
  msg1 <- paste0('\nValue of arg1: ', arg1)
  cat(msg1)
  
  msg2 <- paste0('\nValue of arg2: ', arg2)
  cat(msg2)
  
  cat('\n')
  
  out <- c(msg1, msg2)
  
  return(out)
}
```


After registering the function in the environment (instructions will soon be given), we can change its input as necessary. For example, we can call  `example_fct` with other arguments:

```{r}
# first call
out1 <- example_fct(arg1 = 2, arg2 = 'bcd')

# second call
out2 <- example_fct(arg1 = 10, arg2 = 'dab')
```


Now, let's create a function that does something more useful: it takes as input a numeric vector and outputs its mean. 

```{r, tidy=FALSE}
my_mean_fct <- function(x = c(1, 1, 1, 1)){
  # Calculates the average of input x
  #
  # Args: 
  # 	x: a numerical vector
  #
  # Returns:
  #   The mean of x
  
  out <- sum(x)/length(x)
  
  return(out)
  
}
```

Notice how we've set a comment section after the first curly brace to describe the written function, including its arguments and the returned value.

After writing the function down, register it by executing the code. Let's test it:

```{r}
# testing function my_mean_fct
my_mean <- my_mean_fct(x = 1:100)

# print result
print(my_mean)
```

The mean of a sequence from 1 to 100 is `r my_mean`, as expected. 

If function `my_mean_fct` is called without any input, it will use the _default_ value of `x = c(1, 1, 1, 1)`, with a mean equal to `1`. Let's try it:

```{r}
# calling my_mean_fct without input
my_mean <- my_mean_fct()

# print result
print(my_mean)
```

Again, as expected, the returned value is correct. 


## Using `for` Loops 

A _loop_ command is the most basic computer instruction in any programming language. Briefly, loops allow a structured repetition of code for processing individual items, whatever they are. 

The structure of a _loop_ in R follows:

```{r eval=FALSE}
for (i in i_vec) {
  ...
}
```

Command `for` indicates the beginning of a _loop_. Object `i,` as in `(i in i_vec),` is the iterator -- it will change its value according to each element contained in `i_vec.` 

```{r}
# set seq
my_seq <- seq(-5, 5)

# do loop
for (i in my_seq){
  cat(paste('\nThe value of i is', i))
}
```

We created a sequence from -5 to 5 and presented a text for each element with the `cat` function.

Using nested _loops_, that is, a _loop_ inside of another _loop_ is also possible. See the following example, where we present all the elements of a matrix:

```{r}
# set matrix
my_mat <- matrix(1:9, nrow = 3)

# loop all values of matrix
for (i in seq(1, nrow(my_mat))){
  for (j in seq(1,ncol(my_mat))){
    cat(paste0('\nElement [', i, ', ', j, '] = ', 
               my_mat[i, j]))
  }
}
```

Let's do a more complex example using data files. We will create several files with random data in our computer and save them in a folder named `many_datafiles`.

```{r}
library(tidyverse)

# set number of files to create
n_files <- 10

# set the first part of saved files
pattern_name <- 'myfiles_'

# set dir
out_dir <- 'many_datafiles/'

# test if out.dir exists -- if not, create it
if (!dir.exists(out_dir)) {
  dir.create(out_dir)	
} else {
  # clean up folder before creating new files
  file.remove(list.files(out_dir, 
                         full.names = TRUE))	
}

# set vec with filenames
file_names <- paste0(out_dir, 
                     pattern_name, 
                     seq(1, n_files), '.csv')

# loop it!
for (i_file in file_names){
  # create temp df
  temp_df <- tibble(x = runif(100))
  
  # write it!
  write_csv(x = temp_df, path = i_file)
}
```

Now, let's check if the files are in the folder:

```{r}
# check files
print(list.files(out_dir))
```

As expected, the files are there. To complete the example, we will import the contents of these files and aggregate all information into a single `dataframe` by using another _loop_ and functions `readr::read_csv` and `readr::bind_rows.` 

```{r}
# set empty df
df_agg <- tibble()
for (i_file in file_names){
  # read file
  temp_df <- read_csv(i_file, col_types = cols())
  
  # row bind 
  df_agg <- bind_rows(df_agg, temp_df)
}

glimpse(df_agg)
```

Notice how we bind all `dataframes` within the loop with line `df_agg <- bind_rows(df_agg, temp_df)`. 

Another practical example of using _loops_ is processing data according to groups.

```{r}
library(tidyverse)

# read data
my_f <- afedR::afedR_get_data_file('SP500-Stocks_long.csv')
df_SP500 <- read_csv(my_f,
                     col_types = cols())

# find unique tickers in column ticker
unique_tickers <- unique(df_SP500$ticker)

# create empty df for saving results
tab_out <- tibble()

# loop tickers
for (i_ticker in unique_tickers){
  
  # create temp df with ticker i.ticker
  temp <- df_SP500 %>%
    filter(ticker == i_ticker)
  
  # row bind i.ticker and mean_price
  temp_mean_price <- mean(temp$price.adjusted)
  tab_out <- bind_rows(tab_out,
                       tibble(ticker = i_ticker,
                              mean_price = temp_mean_price))
  
}

# print result
print(head(tab_out))
```

We used the function `unique` to discover the names of all the tickers in the dataset. Soon after, we create an empty _dataframe_ to save the results and a loop for filtering the data of each stock sequentially and averaging its prices.


## Conditional Statements (`if`, `else`, `switch`)

Making binary decisions of type _yes_ or _no_ is common programming practice. In R, we can write them down by using the following structure:

```{r eval=FALSE}
# skeleton for if statement
if (cond){
  
  CodeIfTRUE...
  
} else {
  
  CodeIfFALSE...
  
}
```

The placeholder `cond` is the condition to be evaluated, taking only two values: `TRUE` or `FALSE.` The result of the condition must be a single logical element. 

A practical example based on a _loop_ is presented next: 

```{r}
# set vec and threshold
my_x <- 1:10
my_thresh <- 5

for (i in my_x) {
  if (i > my_thresh){
    cat('\nValue of ', i, 
        ' is higher than ', 
        my_thresh)
  } else {
    cat('\nValue of ', 
        i, 
        ' is lower or equal than ', 
        my_thresh)
  }
}
```

If we want to apply more than one logical condition, we can use the `else if` command as well as `else`: \index{base!else}

```{r}
for (i in my_x){
  if (i > my_thresh){
    cat('\nValue of ', i, ' is higher than ', my_thresh)
  } else if (i==my_thresh) {
    cat('\nValue of ', i, ' is equal to ', my_thresh)
  } else {
    cat('\nValue of ', i, ' is lower than ', my_thresh)
  }
}
```


## Using `apply` Functions

An alternative way of using _loops_ in R is to call functions from the `base::apply` and `purrr::map` family. These are part of the **functional programming** philosophy of R as they require the explicit definition of functions to be used for many items of a vector or `list.` 


### Using `lapply`

Function `base::lapply` takes as input a `list` and a function. It works by passing each element of the input `list` to the function. 

```{r}
# set list
my_l <- list(c(1, 2, 2), 
             c(2:5, NA), 
             c(10:-20))

# use lapply with mean
my_mean_vec <- lapply(X = my_l, 
                      FUN = mean)

# print result
print(my_mean_vec)
```

The result shows the means of each vector in `my_l,` as expected. We could also pass other options to `mean` with `lapply.` See next, where we use `na.rm = TRUE.`

```{r}
# set list
my_l <- list(c(1, 2, 2), c(2:5, NA), 10:-20)

# use lapply with mean
my_mean_vec <- lapply(X = my_l, 
                      FUN = mean, 
                      na.rm=TRUE)

# print result
print(my_mean_vec)
```

As we can see, the extra argument `na.rm = TRUE` is passed to every call to function `mean.` 

Notice the returned object of function `lapply` is always a `list.` Such property is useful whenever you need to apply a function that returns a complex object, such as the estimation of a model, and not a single value.


### Using `sapply`

Function `base::sapply` works similarly to `lapply.` The main difference is in the type of output. While `lapply` returns a list, `sapply` returns an atomic matrix or vector. See the following example: \index{base!sapply}

```{r}
# create list
my_l <- list(1:10, 2:5, 10:-20)

# use sapply
my_mean_vec <- sapply(my_l, mean)

# print result
print(my_mean_vec)
```

Using `sapply` is recommended when the output of the underlying function is an atomic vector. In such cases, it is unnecessary to return a flexible object, such as a `list.`

An important aspect of using `sapply` is the underlying function can return more than one value. 

```{r, tidy=FALSE}
# set list
my_l <- list(x1 = runif(10), 
             x2 = runif(15), 
             x3 = rnorm(1000))

my_mean_fct <- function(x){
  # Returns mean and standard deviation of a vector
  #
  # Args: 
  #	  x - numerical vector
  #
  # Returns:
  #	  Vector as c(mean(x), sd(x))
  
  if (!(class(x) %in% c('numeric','integer'))){
    stop('ERROR: Class of x is not numeric or integer.')
  }
  
  x <- na.omit(x)
  
  out <- c(Mean = mean(x), 
           StDev = sd(x))
  return(out)
  
}

# use sapply
my_vec <- sapply(my_l, my_mean_fct)

# check result
print(my_vec)
```

When there is more than one output in the underlying function, each row in the returned object represents a different output of the function used with `sapply,` in this case, the mean and standard deviation of `x.` The columns indicate the different processed items in `my_l.`  

A practical use of function `sapply` in data analysis is the creation of descriptive tables. 

```{r, tidy=FALSE}
describe_vec <- function(x){
  # Describe numerical vector with mean and other stats
  #
  # Args:
  #	  x - numerical vector
  #
  # Returns:
  #   A vector with mean, maximum and minimum
  
  # error checking
  if (!(class(x) %in% c('numeric','integer'))){
    stop('ERROR: Class of x is not numeric or integer.')
  }
  
  x <- na.omit(x)
  
  # calc vec
  out <- c(mean_price = mean(x), 
           max_price = max(x), 
           min_price = min(x))
  
  return(out)
}
```

Now, let's load the data and apply the function `describe_vec` to the different stocks. \index{describe.vec}

```{r, tidy=FALSE}
library(tidyverse)

# set file and read it
my_f <- afedR::afedR_get_data_file('SP500-Stocks_long.csv')
df_sp500 <- read_csv(my_f,
                     col_types = cols())

# use split to split prices by ticker
my_l <- split(x = df_sp500$price.adjusted, 
              f = df_sp500$ticker)

# use sapply
my_tab <- sapply(X = my_l, FUN = describe_vec)

# check result
print(head(t(my_tab)))
```


### Using `tapply`

Function `tapply` is designed to perform group operations. 

```{r}
# set numeric vec and factor
my_x <- 1:150
my_factor <- factor(c(rep('C',50), 
                      rep('B',50), 
                      rep('A',50)))

# use tapply
my_mean_vec <- tapply(X = my_x, INDEX = my_factor, FUN = mean)

# print result
print(my_mean_vec)
```

Going back to the previous example using stock prices, we can also use `tapply` to reach the same objective of calculating several descriptive statistics for different tickers. Have a look.

```{r}
# use tapply for descriptive stats
my_l_out <- tapply(X = df_sp500$price.adjusted, 
                   INDEX = df_sp500$ticker, 
                   FUN = describe_vec)

# print result				   
print(my_l_out[1:5])
```

The output of `tapply` is a `list` of values. Each element contains a vector from `describe_vec.` Despite showing the same results we've found in the previous example, a `list` is not the recommended type of object for tables. Therefore, we should transform the `list` to a `dataframe`, so we can later export it:

```{r}
# convert list to the dataframe
my_tab <- do.call(what = bind_rows, 
                  args = my_l_out)

# set ticker column
my_tab <- my_tab %>%
  mutate(ticker = names(my_l_out))

# print result
print(head(my_tab))
```


### Using `apply`

The `apply` function follows the same logic as the others, with the main difference being its use in objects with two dimensions.

```{r}
# set matrix and print it
my_mat <- matrix(1:15, nrow = 5)
print(my_mat)

# sum rows with apply and print it
sum_rows <- apply(X = my_mat, MARGIN = 1, FUN = sum)
print(sum_rows)

# sum columns with apply and print it
sum_cols <- apply(X = my_mat, MARGIN = 2, FUN = sum)
print(sum_cols)
```

In the previous example, the `MARGIN` argument sets the orientation of the calculation. With `MARGIN = 1`, function `apply` separates each row as a vector and uses function `sum` in each. With `MARGIN = 2`, the calculation is column-oriented. 



### Using `by`

The `by` function differentiates itself because of its `dataframe` orientation: it splits a `dataframe` into smaller pieces according to a `factor.` 

Look at the next example, where we create a more complex descriptive table using the information on prices and returns. 

```{r}
# load data 
df_sp500 <- read_rds(afedR::afedR_get_data_file(
  'SP500-Stocks-WithRet.rds')
  )

# set function for processing df
describe_vec_with_ret <- function(df_in){
  
  P <- df_in$price.adjusted
  ret <- df_in$ret
  
  out <- c(ticker = df_in$ticker[1],
           MeanPrice= mean(P),
           MaxPrice = max(P),
           MinPrice = min(P),
           MeanRet = mean(ret),
           MaxRet = max(ret),
           MinRet = min(ret))
  
  return(out)
  
}

# apply example_fct for each ticker in df_sp500
my_l <- by(data = df_sp500, 
           INDICES = df_sp500$ticker, 
           FUN = describe_vec_with_ret)

# convert list to dataframe
my_tab <- do.call(what = bind_rows, args = my_l)

# print result
print(head(my_tab))

```

Function `describe_vec_with_ret` was a requirement for using `by`. Notice how its input is a `dataframe` and columns `ret,` and `price.adjusted` is used in its scope. 


## Using package `purrr`

The `tidyverse` universe also offers functions for programming in package `purrr` [@purrr]. The main functions of this package are `map`, `map_dbl`, `map_chr`, `map_int`, `map_lgl`. 

Their use is similar to what we learned from the `apply` family functions, but with some advantages. First, the syntax of `purrr` functions is consistent and allows the use of the pipeline operator. 

```{r}
library(purrr)

# set list
my_l <- list(vec1 = 1:10,
             vec2 = 1:50,
             vec3 = 1:5,
             char1 = letters[1:10])

# get length of objects
res_out <- my_l %>%
  map_int(length) %>%
  print()

# find character objects
res_out <- my_l %>%
  map_lgl(is.character) %>%
  print()
```

Another interesting point about the `purrr` functions is they allow simple access to elements of a `list.` For that, simply enter a position or name in the `map` function:

```{r}

# set list
my_l <- list(vec1 = c(elem1 = 10, elem2 = 20, elem3 = 5),
             char1 = c(elem1 = 40, elem2 = 50, elem3 = 15))

# get second element of each element in list, by position
res_out <- my_l %>% map(2)
print(res_out)

# get third element of each element in list, by name
res_out <- my_l %>% map('elem3')
print(res_out)
```

This functionality is very useful because in many data analysis situations, we are only interested in one element of each object in an extensive `list.`

The great innovation of `purrr` over `base` is the way it can handle errors in the code execution.

Using function `safely` is simple. It encapsulates (encloses) another function and always returns two elements, the result of the call and the error message (if it exists).

```{r, error=TRUE}
library(purrr)

example_fct <- function(x) {
  return(x+1)
}

# ERROR
example_fct('a')
```

Now, let's use `safely` to enclose `example_fct` into another function called `example_fct_safely`:

```{r}
# with safely
example_fct_safely <- safely(example_fct)

class(example_fct_safely('a'))
```

The code `print(example_fct_safely('a'))` resulted in a `list`, not an error. Therefore, when using `safely` with `map`, the return object is the result of calling the function for all cases. See the following example:

```{r}
my_l <- list(1:5,
             'a',
             1:4)

res_out <- my_l %>%
  map(safely(example_fct))

print(res_out)
```

We can easily see that the function had an error in the second element of `my_l.` Going further, if we just wanted the results, without the error, we can write:

```{r}
# only print results without errors
print(res_out %>% map('result'))
```

Or just the error messages:

```{r}
# only print error messages
print(res_out %>% map('error'))
```

An interesting option of `safely` is the choice of output whenever an error occurs. See the next example, where we set an `NA` value every time function `example_fct` results in an error: 

```{r}
my_l <- list(1,
             'a',
             4)

# NA for errors
res_out <- my_l %>%
  map(safely(example_fct,
             otherwise = NA)) %>%
  map_dbl('result')

# print result
print(res_out)
```

Other functions for controlling errors in `purrr` are `possibly` and `quietly.` These functions behave similarly to `safely` and will not be demonstrated here. 


### The `purrr::pmap` function

The `purrr::pmap` is one of the best functional alternatives to loops. Whenever we need to call a function with many different varying arguments (and not just one), `pmap` is the solution. 

As an example, let's consider a function that builds a phrase:

```{r}
build_phrase <- function(name_in, fruit_in, verb_in) {
  my_msg <- paste0('My name is ', name_in,
                   ' and I like to eat ', fruit_in,
                   ' while ', verb_in, '.')
  
  return(my_msg)
}

build_phrase('Joe', 'apple', 'studying')
```

Function `build_phrase` has three text inputs: a name, a fruit and a verb. Suppose we need to create phrases for all combinations of several names, fruits and verbs. 

```{r}
names_vec <- c('Joe', 'Kate')
fruits_vec <- c('kiwi', 'apple')
verb_vec <- c('rowing', 'studying')

my_phrases <- character()
for (i_name in names_vec) {
  for (i_fruit in fruits_vec) {
    for (i_verb in verb_vec) {
      my_phrases <- c(my_phrases, 
                      build_phrase(i_name, i_fruit, i_verb))
    }
  }
}

print(my_phrases)
```

While the code works as expected, a better approach is using `purrr::pmap`. All we need to do is to pass all combinations of arguments to the function:

```{r}
df_grid <- expand.grid(names_vec = names_vec,
                       fruits_vec = fruits_vec,
                       verb_vec = verb_vec)

l_args <- list(name_in = df_grid$names_vec,
               fruit_in = df_grid$fruits_vec,
               verb_in = df_grid$verb_vec)

my_phrases <- purrr::pmap(.l = l_args, 
                          .f = build_phrase)

print(my_phrases)
```

Do notice that the names in `l_args` match the input names in `build_phrase.` The output of `purrr::pmap` is a list, but we could easily transform it into a vector using `as.character`:

```{r}
print(as.character(my_phrases))
```

If necessary, we can also set fixed arguments in `l_args`:

```{r}
l_args <- list(name_in = names_vec,
               fruit_in = 'orange',
               verb_in = 'studying')

my_phrases <- purrr::pmap(.l = l_args, 
                          .f = build_phrase)

print(my_phrases)
```

Whenever you have a situtation where a nested loop is need, using `purrr:pmap` is highly recommended. We will use it whenever necessary throughout the rest of the book.


## Data Manipulation with Package `dplyr`

Package `dplyr` [@dplyr] is very handy for data processing operations. Many loop operations can be replaced with a simpler code structure using `dplyr` functions. 

```{r, echo = FALSE, purl=FALSE}
dplyr_fcts <- ls('package:dplyr')
n_fcts <- length(dplyr_fcts)

installed_pkgs <- installed.packages()
idx <- which(installed_pkgs[, 1] == 'dplyr')

my_ver <- installed_pkgs[, 'Version'][idx]

```


In its current version, `r my_ver`, `dplyr` has `r n_fcts` functions. Describing each functionality would be too exhaustive for this book. Therefore, we will focus on the main functions of the package.


### Group Operations with `dplyr`

The greatest functionality of `dplyr` is in performing group calculation -- commonly called **split-apply-combine**--, that is, we separate the data into groups, apply some function, and finally combine all the results into a new table.

To illustrate the use of the functions `group_by` and `summarise,` we will execute the same example of describing stock prices from the previous section. 

```{r}
library(tidyverse)

# load data
my_f <- afedR::afedR_get_data_file('SP500-Stocks-WithRet.rds')
df_sp500 <- readRDS(my_f)

# group data and calculate stats
my_tab <- df_sp500 %>%
  group_by(ticker) %>%
  summarise(mean_price = mean(price.adjusted),
            max_price = max(price.adjusted),
            min_price = min(price.adjusted),
            max_ret = max(ret),
            min_ret = min(ret))

# check result
print(my_tab)
```

Using `dplyr` is highly recommended when you have to group the data based on more than one factor. 

Let's consider grouping stock data by ticker and the day of the week (Monday, Tuesday…). First, let's use function `weekday` to create a column called `week_day` in `df_sp500`. \index{base!weekday} 

```{r}
# set new col week.day
df_sp500 <- df_sp500 %>%
  mutate(week_day = weekdays(ref.date))

# check result
glimpse(df_sp500)
``` 

Now, we proceed by adding column `week_day` in `group_by.` 

```{r}
# group by ticker and weekday, calculate stats
my_tab <- df_sp500 %>%
  group_by(ticker, week_day) %>%
  summarise(mean_price = mean(price.adjusted), 
            max_price = max(price.adjusted), 
            min_price = min(price.adjusted),
            max.ret = max(ret),
            min.ret = min(ret))

# print result						  
print(my_tab)
```

And that's it! To group the data to a new `factor,` all we need to do is add it in `group_by.` Using `dplyr` to do simple group calculations is straightforward. The resulting code is efficient, self-contained, and elegant. 


### Complex Group Operations with `dplyr`

The previous example shows a simple case of group calculations. We can say it was simple because all of the argument operations in `summarise` had one value as a result. We had a mean for ticker XYZ in weekday `'Monday'`, another means for ticker ZYX in weekday `'Tuesday'`, and so on.

Package `dplyr` also supports more complex operations, where the output is not a single value, but a complex object. 

Let’s look at the following example, where we use stock returns to calculate their accumulated value over time and store it in a `tibble`.

```{r}
# simulated vector of returns
ret <- c(0, rnorm(4, sd= 0.05))

# vector of accumulated returns
acum_ret <- cumprod(1+ret)
print(acum_ret)
```

Vector `acum_ret` represents a multiplier of an investor's portfolio. Based on it, we could track how much the investment is worth each day. Now, let's do the same for all stocks in the SP500, also saving the maximum and minimum value.

```{r}
library(dplyr)

# get acum ret of stocks
my_tab <- df_sp500 %>%
  group_by(ticker) %>%
  do(acum_ret = cumprod(1+.$ret)) %>%
  mutate(last_cumret = acum_ret[length(acum_ret)],
         min_cumret = min(acum_ret))

print(head(my_tab))
```

Notice how column `acum_ret` is not a single value but an atomic vector.

The greatest advantage of using complex group operations with `dplyr` is you can keep the same tabular representation. We can read the object `my_tab` as "for each stock, define a vector of accumulated returns". 

## Exercises

1.  Create a function called `say_my_name` that uses a person's name as input and displays the text _Your name is ..._ in the prompt. It should return `TRUE` at the end of its execution. Within the scope of the function, use comments to describe the purpose of the function, its inputs, and outputs. 

2.  Considering the previous `say_my_name` function, implement a test code for the input. If its class is not `character,` an error is returned to the user. Likewise, make sure the input object has a length equal to one, and not a vector. Test your new function with the wrong inputs to make sure it catches it, as expected. 

3.  Download a database of popular Canadian baby names from [CHHS Data](https://data.chhs.ca.gov/dataset/most-popular-baby-names-2005-current)^[https://data.chhs.ca.gov/dataset/most-popular-baby-names-2005-current]. Import the data into R and, using a _loop_, apply the `say_my_name` function to 15 random names from the database. Tip: In this case, you must manually download the data from the website.

4.  Redo the previous exercise 3 using `sapply` and `purrr::map` commands.

5.  Use package `BatchGetSymbols` to download values for the SP500 index (`^GSPC`), Ibovespa (`'^BVSP'`), FTSE (`'^FSTE'`) and Nikkei 225 (`'^N225'`) from `'2010-01-01'` to the current date. With the imported data, use a _loop_ to calculate average, maximum, and minimum return of each index over the analyzed period.

6.  Redo the previous exercise using the `dplyr` package functions `group_by` and `summarise.`

7.  With the dataset of names from exercise 3, use functions `dplyr::group_by` and `dplyr::summarise` to build a table with the most popular names by year.

8.  CHALLENGE - In [Rstudio CRAN logs](http://cran-logs.rstudio.com/)^[http://cran-logs.rstudio.com/] you can find data regarding the download statistics for the base distribution of R in section _Daily R downloads_. Using your programming skills, import all available data for the current month, and aggregate it into a single file. Which country presents the highest download count for R? 
