---
title: "Analyzing Financial and Economic Data with R"
subtitle: "Chapter 03 - Research Scripts"
author: "Marcelo S. Perlin"
date: "2020-02-15"
output:
  slidy_presentation: default
  ioslides_presentation: default
  beamer_presentation: default

---

## Introduction {#introduction}

```{r, include=FALSE}
my.fig.height <- 3
my.fig.width <- 4
my.out.width <- '100%'

book.site.zip <- 'https://www.msperlin.com/blog/static/afedr-files/afedr_files.zip'
```

Unlike other software designs, every research script has clear consecutive steps to achieve its goal. 

1. **Importation of data**: Raw (original) data is imported from a local file or the internet. 

2. **Cleaning and structuring the data**: The raw data imported in the previous step is further cleaned and structured according to the need of the research. Preferably, at the end of this stage, there should be a couple of final datasets that will be used in the next stage. 

3. **Visual analysis and hypothesis testing**: After cleansing and structuring the data, the work continues with implementing the visual analysis and hypothesis testing. 

4. **Reporting the results**: The final stage of a research script is reporting the results. Likely, we will be exporting selected tables and figures from R to a text processing software such as Latex, Writer (LibreOffice) or Word (Microsoft). 

Each of the mentioned steps can be structured in a single _.R_ script or in several separate files.

If you are working with multiple files, one suggestion is to create a naming structure that informs the steps of the research in an intuitive way. The practical effect is that using a number in the first letter of the filenames clarifies the order of execution. 

An example would be to name the data importing code as  `01-Import-and-clean-data.R`, the modeling code as `02-build-report-models.R` and so on. 


## Folder Structure {#directories}

A proper folder structure also benefits the reproducibility and organization of research. 

A suggestion for an effective folder structure is to create a single directory and, within it, create subdirectories for each input and output element. 

	/Capital Markets and Inflation/
		/data/
			stock_indices.csv
			inflation_data.csv
		/figs/
			SP500_and_inflation.png
		/tables/
			Table1_descriptive_table.tex
			Table2_model_results.tex
		/R-Fcts/
			fct_models.R
			fct_clean_data.R
		0-run-it-all.R
		1-import-and-clean-data.R
		2-run-research.R

The research code should also be self-contained, with all files available within a sub-folder of the root directory. 


## Important Aspects of a Research Script

**know your data!**. 

- How was the data collected? To what purpose?
- How do the available data compare with data used in other studies?
- Is there any possibility of bias within the data collection?

**A great power comes with great responsibility**

- A single misplace line in a code can easily bias and invalidate your research. 

Always be skeptical about your own work:

- Do the descriptive statistics of the variables faithfully report the database?
- Is there any relationship between the variables that can be verified in the descriptive table?
- Do the main findings of the research make sense to the current literature of the subject? If not, how to explain them?
- Is it possible that a _bug_ in the code has produced the results?


## Exercises

01. Imagine a survey regarding your household budget over time. Data is stored as separate spreadsheets, one for each year, from 2009 to 2019. The objective of the research is to understand if it is possible to buy a home property in 5 years. Based on this, detail the elements in each stage of the study as a sequence, from importing the data to constructing the report. 

02. Based on the previous exercise, create a folder structure on your computer to accommodate the research. Create dummy files with no content for each subdirectory (see folder structure at section \@ref(directories)). Note that the creation of the directories can be done with function `dir.create`.
